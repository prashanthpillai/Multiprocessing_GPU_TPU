{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9f23661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import transformers\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModelForMaskedLM, BertForMaskedLM\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import DataCollatorForLanguageModeling, DataCollatorForWholeWordMask\n",
    "from transformers import EarlyStoppingCallback, IntervalStrategy, SchedulerType\n",
    "import math\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2aa217f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"m3rg-iitd/matscibert\"\n",
    "tokenizer_checkpoint = \"m3rg-iitd/matscibert\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_checkpoint)\n",
    "config = AutoConfig.from_pretrained(model_checkpoint)\n",
    "#model = AutoModelForMaskedLM.from_config(config)\n",
    "model = BertForMaskedLM.from_pretrained(model_checkpoint)\n",
    "model = BertForMaskedLM.from_pretrained('model_save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64ece879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(31090, 768, padding_idx=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a222855f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     Text    Source\n",
      "0       Further reading == Chen, Gang. Nanoscale Energ...      Wiki\n",
      "1       Cased hole completion === This involves runnin...      Wiki\n",
      "2       With a roar like a hundred express trains raci...      Wiki\n",
      "3       Reflection seismology === Seismic reflection i...      Wiki\n",
      "4       Oil wells === The question of what constituted...      Wiki\n",
      "...                                                   ...       ...\n",
      "199317  Seismic curvature attributes, as being second-...  Onepetro\n",
      "199318  A 10-years research program at the U. of Stava...  Onepetro\n",
      "199319  A case study of one of the reservoirs of X Fie...  Onepetro\n",
      "199320  In El Huemul field, four main subvertical feat...  Onepetro\n",
      "199321  The problem of radial crack propagation from a...  Onepetro\n",
      "\n",
      "[199322 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "geo_df = pd.read_csv('./datasets/Geo_Dataset/Training_paras_for_BERT.csv')\n",
    "#geo_df = geo_df.loc[geo_df['Source']!='Onepetro']\n",
    "#geo_df = geo_df.reset_index(drop=True)\n",
    "print(geo_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9f611b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"Text\"])\n",
    "\n",
    "def group_texts(examples, block_size=512):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "        # customize this part to your needs.\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d599ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(geo_df, test_size=0.2, random_state=100)\n",
    "train = train['Text']\n",
    "val = val['Text']\n",
    "train.to_csv('./datasets/Geo_Dataset/Train.csv', index=False)\n",
    "val.to_csv('./datasets/Geo_Dataset/Val.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38e4550c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-3bfa6b1dd7c5cf2a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/jupyter/.cache/huggingface/datasets/csv/default-3bfa6b1dd7c5cf2a/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c2c2320cf70485cbe38d6b42834d43a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a3b33f84cea4ca5b83b732e15748c94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/jupyter/.cache/huggingface/datasets/csv/default-3bfa6b1dd7c5cf2a/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27dd04f3b9aa42298b7efbea6c91fadd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_files = {}\n",
    "data_files[\"train\"] = './datasets/Geo_Dataset/Train.csv'\n",
    "data_files[\"validation\"] = './datasets/Geo_Dataset/Val.csv'\n",
    "extension='csv'\n",
    "raw_datasets = load_dataset(extension, data_files=data_files)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f18ac684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbbcc5b3250a40c7b848f6cb2d6dac99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fd66b4b24744764b2cb08c671e7570b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fe26e0325104338984190011d3d5e38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa98751ce2ca40a88bce247246f2e9a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#4:   0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b6c33ec5e514043ac2971fb4f85ef95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#5:   0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57f5571725ea463ead6cf8ab4d0221ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b86c9f8031f34f4a87719252a831bd0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#7:   0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b250e43d23cb4a119a28316b94a2ec17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#6:   0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "457ff576bc0c43beaf9e6468fb274b22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85d97ef4f7284f2f9d7583de757d9ba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d7b4c486cf94e45a951bd33e8e178f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf96da472902488290233115ddaf03b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#4:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7717849e4626446582b6b60692deec19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#5:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f32e9ca2e734bd9b66c5571a63d047b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "930e1644ed0044239f22efd01cabfe6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#6:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17670ba80f6142db8f92c6d312dbf693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#7:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dfdfb02e5194568a1464585de0f5ac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/40 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "236a2a125faa426d8e2ec87a5f18d580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/40 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e78b85efe2f4d8ab26a6c870083295c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/40 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79c73cc2dce14c0dab4936255152df38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/40 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61b82a60298440fe9a77b8475d480806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68b25757090146e5a81578035a19e445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c7e71e388064f278fd742c70835c3d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bab52a864204a36a83be6ea36327c4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True, num_proc=8, remove_columns=[\"Text\"])\n",
    "lm_datasets = tokenized_datasets.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3af39df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 123236 , Eval size: 30828 , Steps: 9756.183333333334 , Gradient accum: 5\n"
     ]
    }
   ],
   "source": [
    "NGPU = torch.cuda.device_count()\n",
    "EPOCHS=19\n",
    "TRAIN_BATCHSIZE = 6\n",
    "VAL_BATCHSIZE = 6\n",
    "TRAIN_SIZE = len(lm_datasets[\"train\"])\n",
    "EVAL_SIZE = len(lm_datasets[\"validation\"])\n",
    "GRADACCUM = int(256/(TRAIN_BATCHSIZE * NGPU))\n",
    "total_steps = TRAIN_SIZE/(TRAIN_BATCHSIZE * NGPU * GRADACCUM) * EPOCHS\n",
    "print('Train size:', TRAIN_SIZE,', Eval size:',EVAL_SIZE, ', Steps:',total_steps, ', Gradient accum:', GRADACCUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7da1ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)\n",
    "data_collator = DataCollatorForWholeWordMask(tokenizer=tokenizer, mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0157e9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    f\"{model_checkpoint}-geo\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    #evaluation_strategy = IntervalStrategy.STEPS,\n",
    "    num_train_epochs=EPOCHS, #default 3\n",
    "    per_device_train_batch_size=TRAIN_BATCHSIZE, #default 8\n",
    "    per_device_eval_batch_size=VAL_BATCHSIZE, #default 8\n",
    "    gradient_accumulation_steps=GRADACCUM, #default 1\n",
    "    warmup_ratio=0.048,\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=1e-2,\n",
    "    adam_beta1=0.9,\n",
    "    adam_beta2=0.98,\n",
    "    adam_epsilon=1e-6,\n",
    "    max_grad_norm=0.0,\n",
    "    push_to_hub=False,\n",
    "    logging_steps=100,\n",
    "    load_best_model_at_end=True\n",
    "    #lr_scheduler_type=SchedulerType.LINEAR\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_datasets[\"train\"],\n",
    "    eval_dataset=lm_datasets[\"validation\"],\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=3)],\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead3285e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 123236\n",
      "  Num Epochs = 19\n",
      "  Instantaneous batch size per device = 6\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 240\n",
      "  Gradient Accumulation steps = 5\n",
      "  Total optimization steps = 9747\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8791' max='9747' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8791/9747 11:43:49 < 1:16:33, 0.21 it/s, Epoch 17.13/19]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.945900</td>\n",
       "      <td>1.856643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.883900</td>\n",
       "      <td>1.804067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.840100</td>\n",
       "      <td>1.769360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.808300</td>\n",
       "      <td>1.742321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.782000</td>\n",
       "      <td>1.725365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.763500</td>\n",
       "      <td>1.707510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.747400</td>\n",
       "      <td>1.697418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.724700</td>\n",
       "      <td>1.681129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.707500</td>\n",
       "      <td>1.667323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.701500</td>\n",
       "      <td>1.661141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.685400</td>\n",
       "      <td>1.649551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.676500</td>\n",
       "      <td>1.641170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.666200</td>\n",
       "      <td>1.638000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.654800</td>\n",
       "      <td>1.629138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.646000</td>\n",
       "      <td>1.623362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.634800</td>\n",
       "      <td>1.616273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.630600</td>\n",
       "      <td>1.612401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 30828\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to m3rg-iitd/matscibert-geo/checkpoint-513\n",
      "Configuration saved in m3rg-iitd/matscibert-geo/checkpoint-513/config.json\n",
      "Model weights saved in m3rg-iitd/matscibert-geo/checkpoint-513/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30828\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to m3rg-iitd/matscibert-geo/checkpoint-1026\n",
      "Configuration saved in m3rg-iitd/matscibert-geo/checkpoint-1026/config.json\n",
      "Model weights saved in m3rg-iitd/matscibert-geo/checkpoint-1026/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30828\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to m3rg-iitd/matscibert-geo/checkpoint-1539\n",
      "Configuration saved in m3rg-iitd/matscibert-geo/checkpoint-1539/config.json\n",
      "Model weights saved in m3rg-iitd/matscibert-geo/checkpoint-1539/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30828\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to m3rg-iitd/matscibert-geo/checkpoint-2052\n",
      "Configuration saved in m3rg-iitd/matscibert-geo/checkpoint-2052/config.json\n",
      "Model weights saved in m3rg-iitd/matscibert-geo/checkpoint-2052/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30828\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to m3rg-iitd/matscibert-geo/checkpoint-2565\n",
      "Configuration saved in m3rg-iitd/matscibert-geo/checkpoint-2565/config.json\n",
      "Model weights saved in m3rg-iitd/matscibert-geo/checkpoint-2565/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30828\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to m3rg-iitd/matscibert-geo/checkpoint-3078\n",
      "Configuration saved in m3rg-iitd/matscibert-geo/checkpoint-3078/config.json\n",
      "Model weights saved in m3rg-iitd/matscibert-geo/checkpoint-3078/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30828\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to m3rg-iitd/matscibert-geo/checkpoint-3591\n",
      "Configuration saved in m3rg-iitd/matscibert-geo/checkpoint-3591/config.json\n",
      "Model weights saved in m3rg-iitd/matscibert-geo/checkpoint-3591/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30828\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to m3rg-iitd/matscibert-geo/checkpoint-4104\n",
      "Configuration saved in m3rg-iitd/matscibert-geo/checkpoint-4104/config.json\n",
      "Model weights saved in m3rg-iitd/matscibert-geo/checkpoint-4104/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30828\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to m3rg-iitd/matscibert-geo/checkpoint-4617\n",
      "Configuration saved in m3rg-iitd/matscibert-geo/checkpoint-4617/config.json\n",
      "Model weights saved in m3rg-iitd/matscibert-geo/checkpoint-4617/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30828\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to m3rg-iitd/matscibert-geo/checkpoint-5130\n",
      "Configuration saved in m3rg-iitd/matscibert-geo/checkpoint-5130/config.json\n",
      "Model weights saved in m3rg-iitd/matscibert-geo/checkpoint-5130/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30828\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to m3rg-iitd/matscibert-geo/checkpoint-5643\n",
      "Configuration saved in m3rg-iitd/matscibert-geo/checkpoint-5643/config.json\n",
      "Model weights saved in m3rg-iitd/matscibert-geo/checkpoint-5643/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30828\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to m3rg-iitd/matscibert-geo/checkpoint-6156\n",
      "Configuration saved in m3rg-iitd/matscibert-geo/checkpoint-6156/config.json\n",
      "Model weights saved in m3rg-iitd/matscibert-geo/checkpoint-6156/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30828\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to m3rg-iitd/matscibert-geo/checkpoint-6669\n",
      "Configuration saved in m3rg-iitd/matscibert-geo/checkpoint-6669/config.json\n",
      "Model weights saved in m3rg-iitd/matscibert-geo/checkpoint-6669/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30828\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to m3rg-iitd/matscibert-geo/checkpoint-7182\n",
      "Configuration saved in m3rg-iitd/matscibert-geo/checkpoint-7182/config.json\n",
      "Model weights saved in m3rg-iitd/matscibert-geo/checkpoint-7182/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30828\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to m3rg-iitd/matscibert-geo/checkpoint-7695\n",
      "Configuration saved in m3rg-iitd/matscibert-geo/checkpoint-7695/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in m3rg-iitd/matscibert-geo/checkpoint-7695/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30828\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to m3rg-iitd/matscibert-geo/checkpoint-8208\n",
      "Configuration saved in m3rg-iitd/matscibert-geo/checkpoint-8208/config.json\n",
      "Model weights saved in m3rg-iitd/matscibert-geo/checkpoint-8208/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30828\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to m3rg-iitd/matscibert-geo/checkpoint-8721\n",
      "Configuration saved in m3rg-iitd/matscibert-geo/checkpoint-8721/config.json\n",
      "Model weights saved in m3rg-iitd/matscibert-geo/checkpoint-8721/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "model.save_pretrained('model_save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a15b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''train_dataset = lm_datasets[\"train\"]\n",
    "eval_dataset = lm_datasets[\"validation\"]\n",
    "\n",
    "train_output = trainer.evaluate(train_dataset)\n",
    "eval_output = trainer.evaluate()\n",
    "print(train_output)\n",
    "print('----')\n",
    "print(eval_output)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b280e95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134f5da1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-9.m81",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m81"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
